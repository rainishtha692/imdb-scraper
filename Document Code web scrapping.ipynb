{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6adc080-567a-439b-af47-98ac8a4be332",
   "metadata": {},
   "source": [
    "INTRODUCTION\n",
    "#  IMDb Top 100 Movies Web Scraper (Selenium & Python)\n",
    "##  Introduction\n",
    "\n",
    "This Jupyter Notebook scrapes IMDb's Top 100 Movies and extracts:\n",
    "-  Movie Title\n",
    "-  Release Year\n",
    "-  IMDb Rating\n",
    "\n",
    "It uses Selenium WebDriver, which automates web browsers to interact with dynamic websites like IMDb.\n",
    "\n",
    "---\n",
    "\n",
    "###  Why Selenium?\n",
    "IMDb dynamically loads content using JavaScript, making static scrapers (like BeautifulSoup) less effective.\n",
    "Selenium **automates the browser** to load and extract the required data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90cc55-5c13-4872-ad45-4c85763e1a3a",
   "metadata": {},
   "source": [
    "Install & Import Dependencies\n",
    "## Install & Import Dependencies\n",
    "Before running the script, ensure all required libraries are installed.\n",
    "\n",
    "To install them, run:\n",
    "```bash\n",
    "pip install selenium pandas\n",
    "pip install selenium pandas --#run this only it is not insatlled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb82272-fa6e-4b49-9da1-a7a2b1a957a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from selenium import webdriver  # Automate browser interaction\n",
    "from selenium.webdriver.common.by import By  # Locate elements on a webpage\n",
    "from selenium.webdriver.chrome.options import Options  # Configure Chrome behavior\n",
    "from selenium.webdriver.chrome.service import Service  # Manage ChromeDriver execution\n",
    "import pandas as pd  # Handle extracted data\n",
    "import time  # Introduce delays to allow page loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26dd2ae-99c0-4c89-8014-85a11abbd75b",
   "metadata": {},
   "source": [
    "Setup ChromeDriver & Open IMDb Page\n",
    "\n",
    "## Setting Up WebDriver\n",
    "To interact with IMDb, Selenium requires ChromeDriver, which controls Google Chrome.\n",
    "\n",
    "### üìå Steps:\n",
    "1. Find your Chrome version:\n",
    "   - Open Chrome and go to: `chrome://settings/help`\n",
    "   - Note the version (e.g., Version 121.0.0.0)\n",
    "   \n",
    "2. Download the matching ChromeDriver:\n",
    "   - Visit: [ChromeDriver Website](https://sites.google.com/chromium.org/driver/)\n",
    "   - Download the version matching your Chrome.\n",
    "   - Extract `chromedriver.exe` and copy its path.\n",
    "\n",
    "3. Update the script: Replace `chrome_driver_path` with your actual path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e3b36-d68f-4c53-ac08-02db968953a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to ChromeDriver (Change this to your actual path)\n",
    "chrome_driver_path = r\"C:\\Users\\Acer\\Documents\\chromedriver-win64\\chromedriver.exe\" ---## Path for chromedriver\n",
    "\n",
    "# Set up Chrome WebDriver options\n",
    "options = Options() # creates an instance of options, which is used to set preferences for hpw chrome behaves when controlled by selenium.\n",
    "options.add_argument('--headless')  # Run in headless mode (no UI) #Headless mode is useful for automation and web scraping because it improves performance and prevents UI pop-ups\n",
    "\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')  # Avoid bot detection ,Disabling this makes the automation look more like a real user\n",
    "\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\")  # ## Set a real user-agent -Sets a custom user-agent to make the request appear as if it is coming from a real browser instead of Selenium/This user-agent mimics a real Chrome browser on Windows.\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=Service(chrome_driver_path), options=options)\n",
    "\n",
    "# Open IMDb Top 250 Movies page\n",
    "url = 'https://www.imdb.com/chart/top/'\n",
    "driver.get(url)\n",
    "\n",
    "# Allow time for page to fully load\n",
    "time.sleep(10)  # Adjust based on network speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38576e8-c17e-4682-9f5f-8ea0d853bbd1",
   "metadata": {},
   "source": [
    " Extract Movie Titles, Years, and Ratings\n",
    "##  Extract Movie Titles, Years & Ratings\n",
    "Once the IMDb page loads, we extract:\n",
    "-  Title: Movie name without ranking\n",
    "-  Year: Release year\n",
    "- Rating: IMDb rating (out of 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29799e-f9e7-48bd-b29d-01877281bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate all movie list elements on IMDb\n",
    "movies = driver.find_elements(By.XPATH, '//li[contains(@class,\"ipc-metadata-list-summary-item\")]') # The find_elements function returns a list of WebElements matching the specified XPath\n",
    " #Uses contains(@class,\"ipc-metadata-list-summary-item\") to match list elements that contain movie information.\n",
    "\n",
    "# Initialize an empty list to store extracted data\n",
    "movie_data = [] #Creates an empty list to store the extracted movie details.\n",
    " \n",
    "# Loop through first 100 movies (Modify if needed)\n",
    "for movie in movies[:100]:  # This loops through the first 100 movies from the IMDb page\n",
    "    try:\n",
    "        # Extract movie title (Remove ranking number)\n",
    "        title_raw = movie.find_element(By.XPATH, './/div[contains(@class,\"ipc-title\")]/a/h3').text #The XPath .//div[contains(@class,\"ipc-title\")]/a/h3 locates the title element inside each movie's list item.\n",
    "        title = title_raw.split('. ', 1)[-1]  # Remove number prefix #title_raw.split('. ', 1)[-1] removes the ranking prefix (e.g., \"1. The Shawshank Redemption\" ‚Üí \"The Shawshank Redemption\").\n",
    "\n",
    "\n",
    "        # Extract release year\n",
    "        year = movie.find_element(By.XPATH, './/div[contains(@class,\"cli-title-metadata\")]/span[contains(@class,\"cli-title-metadata-item\")][1]').text #The XPath selects the first span inside the <div> containing metadata (like year, duration, etc.\n",
    "\n",
    "        # Extract IMDb rating\n",
    "        rating = movie.find_element(By.XPATH, './/span[contains(@class,\"ipc-rating-star--rating\")]').text.split()[0] # .text.split()[0] extracts the rating number and ignores extra text.\n",
    "\n",
    "        # Store extracted data\n",
    "        movie_data.append({'Title': title, 'Year': year, 'Rating': rating}) #Appends a dictionary ({'Title': title, 'Year': year, 'Rating': rating}) to the movie_data list.\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping a movie due to error: {e}\")  # Why? If an element is missing or there's a Selenium error, this prevents the script from crashing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8993a-aafe-477c-90d6-3a9b128c9941",
   "metadata": {},
   "source": [
    "## Now that you have successfully scraped IMDb Top 100 movies, you need to clean the dataset to ensure its quality before further analysis.\n",
    "\n",
    "# Load IMDb Data & Check Initial Structure\n",
    "## Step 1: Load IMDb Data & Check Initial Structure\n",
    "Before cleaning, let's load the scraped data and inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbaed3-4f5a-44f7-ab51-510621aeecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = r'C:\\Users\\Acer\\Documents\\BDA3.3\\Project 1- Web scraping\\imdb_top_100_movies.csv'\n",
    "try:\n",
    "    df = pd.read_csv(csv_path, encoding='latin1')  # Use 'ISO-8859-1' if needed\n",
    "    print(\"‚úÖ File successfully loaded!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading file: {e}\")\n",
    "\n",
    "print(\"\\nüîπ Dataset Overview:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec024228-eeb9-40d2-8022-6710b50ed775",
   "metadata": {},
   "source": [
    " Trim Whitespace from Text Fields\n",
    "\n",
    "To remove extra spaces that might cause inconsistencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75bd408-5a2f-4e9c-8294-adc630774b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].str.strip()\n",
    "df['Year'] = df['Year'].astype(str).str.strip()\n",
    "df['Rating'] = df['Rating'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c4d426-3694-40d7-8379-c0eb515c7503",
   "metadata": {},
   "source": [
    "Convert Data Types\n",
    "\n",
    "To ensure numerical values are properly formatted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79f5ab-0dde-4820-a5b2-1a187822066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')  # Convert Year to integer\n",
    "df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')  # Convert Rating to float\n",
    "\n",
    "df = df.dropna()\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "df['Rating'] = df['Rating'].astype(float) #If any conversion fails, those rows are dropped:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3422573-ecd2-458d-8f9e-fc04e1909d05",
   "metadata": {},
   "source": [
    "Remove Duplicate Entries\n",
    "\n",
    "Duplicate records are removed to maintain data integrity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206fbf26-c9bb-4bc1-a944-daf3633536fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2f2e2-276a-44d9-85bb-a0ae0969190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save the Cleaned Dataset\n",
    "\n",
    "After cleaning, the dataset is saved as a new CSV file:\n",
    "\n",
    "clean_csv_path = r'C:\\Users\\Acer\\Documents\\BDA3.3\\Project 1- Web scraping\\imdb_top_100_movies_cleaned.csv'\n",
    "df.to_csv(clean_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
